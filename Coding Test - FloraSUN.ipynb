{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70527156",
   "metadata": {},
   "source": [
    "## Coding test - Flora Y. SUN - 18th June 2023\n",
    "Note: all the \"we\" in the following sections are \"academic we\". This project is finished solely by Flora Y. SUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e75300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import datetime as dt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6d3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data\n",
    "df = pd.read_csv('data.csv').dropna()\n",
    "df.rename(columns={'ticker': 'stock', 'last': 'price'}, inplace=True)\n",
    "date_format = '%Y-%m-%d'\n",
    "df['date'] = df['date'].apply(lambda x: dt.datetime.strptime(x, date_format))\n",
    "df['year'] = df['date'].apply(lambda x: x.year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3898950",
   "metadata": {},
   "source": [
    "## 0 - Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c1f8d15",
   "metadata": {},
   "source": [
    "【General Ideas】\n",
    "\n",
    "1. We used data before year 2019 for model training and used data in or after 2019 for backtesting.\n",
    "2. Stock-price prediction: For each stock, we build an ensumble model consisting of **SVR, Random Forest, GBM, LSTM** on the training set, and then apply the model on the testing set to predict the stock price. We used price of the last 30 days as predictors, while in reality we may change the training step to improve the performance of our model.\n",
    "3. Backtesting: After we got the predicted price value, we moved on to the backtesting session, where we long the 10% most undervalued stocks and short the 10% most overvalued stocks on every trading day, assuming we long/short stocks with equal weight (Alternatively, if we have data on market value, we may also trade stocks based on market value)\n",
    "\n",
    "【Weak Model Selection】\n",
    "1. SVR: SVR is a classic machine learning model and it does not require independece between observations, thus our time-series data does not contradict with the model assumption. \n",
    "2. Random Forest: Random forest is a tree-based model. It build multiple deep trees simultaneously. While building each tree, it conducts boostrap to select a subset of observations and a subset of variables for modelling.\n",
    "3. GBM: GBM is also a tree-based model. It build multiple shallow trees one by one. Ideally we may use XGBoost to train a model. However, it would be better to build a XGBoost model based on a well-trained basic/stochastic GBM model. Since we skipped this part.\n",
    "4. LSTM: we tried LSTM as this neutral network can \"memorize\" historical information and call those information when necessary. It has been widely used to handle time-series data or text data (essentially data that require the model to \"memorize\" the previous things).\n",
    "5. Notes\n",
    "    - We did not try OLS since it requires independence across observations. Time-series apparently violate this assumption.\n",
    "    - we did not try naive bayes since naive bayes requires independence across predictors. while our predictors are historical data of the focal stock, the model assumption may be violated significantly.\n",
    "\n",
    "【Ensemble Model】\n",
    " - We took the average value predicted by the weak models as the final value as some models may overfit while other may underfit. However, in our case, since we did not put too much attention on the hyperparameter tuning, it is likely that all models are underfit. We still put this step here as in reality we may need to consider this.\n",
    "\n",
    "【Future works along this vein】\n",
    " - We did not put too much attention on hyperparameter tuneing since that process may take too much time. However, we may consider improve the model by tuneing hyperparameters.\n",
    "\n",
    "【Adding more information】\n",
    " - Should we have more information (or more time to collect more information), we may consider incorporating more factors into our analysis. Those factors should be able to help us to predict the stock price. For new factors, we may conduct factor analysis (pay attention to IC, IR etc.) and test the stock selection performance based on backtesting (pay attention to the relative performance of stocks located in each factor-value-quantile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d25c016",
   "metadata": {},
   "source": [
    "## 1- Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9297cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preprocessing\n",
    "\n",
    "### get the stocklist\n",
    "stocklist = list(set(df.stock.values.flatten()))\n",
    "\n",
    "### get the training step - use the last 30 days to predict the next day\n",
    "training_step = 30\n",
    "\n",
    "### get the training dict and testing dict.\n",
    "### key: stock name\n",
    "### value: dataframe containing the training data/testing data\n",
    "stock_dict = {}\n",
    "\n",
    "for stock in stocklist:\n",
    "    stock_df = df.iloc[np.where(df.stock == stock)[0], :]\n",
    "    # only keep the stock with more than 500 data points in training and testing sets\n",
    "    if stock_df[stock_df.year < 2019].shape[0] > 500 and stock_df[stock_df.year >= 2019].shape[0] > 500:\n",
    "        stock_dict[stock] = stock_df\n",
    "    \n",
    "    def get_training_dataset(stock_df, normalize):\n",
    "        if normalize:\n",
    "            stock_nor = stock_df.copy(deep=True)\n",
    "            global scaler\n",
    "            scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "            price = scaler.fit_transform(stock_df[['price']]).reshape(-1)\n",
    "            volume = scaler.fit_transform(stock_df[['volume']]).reshape(-1)\n",
    "            parameters = scaler.fit(stock_df[['price']])\n",
    "    \n",
    "            stock_nor['price']=price\n",
    "            stock_nor['volume']=volume\n",
    "            stock_df = stock_nor\n",
    "        else:\n",
    "            stock_df = stock_df.copy()\n",
    "        \n",
    "        for i in range(1, 1+training_step):\n",
    "            stock_df['price_lastday{}'.format(i)] = stock_df.price.shift(i)\n",
    "            stock_df['volume_lastday{}'.format(i)] = stock_df.volume.shift(i)\n",
    "        stock_df.dropna(inplace=True)\n",
    "        stock_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        train_df = stock_df[stock_df.year < 2019]\n",
    "        test_df = stock_df[stock_df.year >= 2019]\n",
    "        return train_df, test_df\n",
    "    \n",
    "    def un_normalize(normalized_series):\n",
    "        un_normalized = scaler.inverse_transform(np.array(normalized_series).reshape(-1,1))\n",
    "        return un_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6fb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trytrain = train_dict['8252 JT'].copy()\n",
    "#trytest = test_dict['8252 JT'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3d0866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ML_model(stock_df): \n",
    "    train_df, test_df = get_training_dataset(stock_df, normalize=False)\n",
    "    train_y = train_df.iloc[:, 2].values\n",
    "    train_x = train_df.iloc[:, 5:].values\n",
    "    test_x = test_df.iloc[:, 5:].values\n",
    "\n",
    "    model_svr = SVR()\n",
    "    model_svr.fit(train_x, train_y)\n",
    "    ## There should be hyperparameter tuneing process, yet we skip it here. \n",
    "    ## If we are to conduct the tuneing process, we can use the following code as the starting point:\n",
    "    \n",
    "    # n_folds = 5\n",
    "    # parameters = {'kernel':('rbf', ' linear', 'poly'), 'C': [1, 5, 10]}\n",
    "    # clf = GridSearchCV(model_svr, parameters, cv=n_folds)\n",
    "    # clf.fit(train_x, train_y)\n",
    "    # pred_y_svm = clf.predict(test_x)\n",
    "\n",
    "    model_rf = RandomForestRegressor()\n",
    "    model_rf.fit(train_x, train_y)\n",
    "\n",
    "    model_gbm = GradientBoostingRegressor()\n",
    "    model_gbm.fit(train_x, train_y)\n",
    "\n",
    "    pred_y_svm = model_svr.predict(test_x)\n",
    "    pred_y_rf = model_rf.predict(test_x)\n",
    "    pred_y_gbm = model_gbm.predict(test_x)\n",
    "    \n",
    "    test_df['pred_price_SVM'] = pred_y_svm\n",
    "    test_df['pred_price_RF'] = pred_y_rf\n",
    "    test_df['pred_price_GBM'] = pred_y_gbm\n",
    "\n",
    "    results_df = test_df.loc[:, [\"date\",'pred_price_SVM', 'pred_price_RF', 'pred_price_GBM']] \n",
    "    stock_df = pd.merge(stock_df, results_df, on ='date')\n",
    "    \n",
    "    return stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e2c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(stock_df):\n",
    "    train_df, test_df = get_training_dataset(stock_df, normalize=True)\n",
    "    xtrain_price = []\n",
    "    xtrain_volume = []\n",
    "    \n",
    "    train_price_df = train_df.filter(like='price_', axis=1)\n",
    "    train_volume_df = train_df.filter(like='volume_', axis=1)\n",
    "    \n",
    "    for i in range(train_price_df.shape[0]):\n",
    "        xtrain_price.append(train_price_df.iloc[i])\n",
    "    for i in range(train_volume_df.shape[0]):\n",
    "        xtrain_volume.append(train_volume_df.iloc[i])\n",
    "    xtrain_price, xtrain_volume = np.array(xtrain_price), np.array(xtrain_volume)\n",
    "    \n",
    "    X_train = np.stack([xtrain_price], axis = 2)\n",
    "    # add xtrain_volume to np.stack list if want to add volume as a feature\n",
    "    y_train = np.array(train_df.price)\n",
    "    y_train = np.reshape(y_train,(len(y_train),1))\n",
    "    \n",
    "    #return X_train.shape(), y_train.shape()\n",
    "    \n",
    "    regressor = Sequential()\n",
    "    regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    regressor.add(LSTM(units = 25))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    #regressor.add(Dense(units = 50, activation='relu'))\n",
    "    regressor.add(Dense(units=1))\n",
    "\n",
    "    regressor.compile(optimizer='adam', loss = 'mean_squared_error')\n",
    "    regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)\n",
    "\n",
    "    xtest_price = []\n",
    "    xtest_volume = []\n",
    "    \n",
    "    test_price_df = test_df.filter(like='price_', axis=1)\n",
    "    test_volume_df = test_df.filter(like='volume_', axis=1)\n",
    "    \n",
    "    for i in range(test_price_df.shape[0]):\n",
    "        xtest_price.append(test_price_df.iloc[i])\n",
    "    for i in range(test_volume_df.shape[0]):\n",
    "        xtest_volume.append(test_volume_df.iloc[i])\n",
    "    xtest_price, xtest_volume = np.array(xtest_price), np.array(xtest_volume)\n",
    "    \n",
    "    X_test = np.stack([xtest_price], axis = 2)\n",
    "    y_prediction = regressor.predict(X_test)\n",
    "\n",
    "    y_test_df = test_df.price\n",
    "\n",
    "    predict_df = pd.DataFrame(y_prediction)\n",
    "    \n",
    "    true_y_test = pd.DataFrame(un_normalize(y_test_df))\n",
    "    true_y_prediction = pd.DataFrame(un_normalize(y_prediction))\n",
    "    \n",
    "    test_df['pred_price_LSTM'] = un_normalize(y_prediction)\n",
    "    results_df = test_df.loc[:, [\"date\",'pred_price_LSTM']] \n",
    "    stock_df = pd.merge(stock_df, results_df, on ='date')\n",
    "    \n",
    "    return stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e425dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 20ms/step - loss: 0.0215\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0064\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0063\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0059\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0057\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0053\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0041\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0045\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0045\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0042\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0037\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0032\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0034\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0029\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0028\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0030\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0032\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0027\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0024\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0025\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0030\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0027\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0029\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0027\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0025\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0024\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0025\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0026\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0020\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0021\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0019\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0018\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0021\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0020\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0021\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0024\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0024\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0016\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 20ms/step - loss: 0.0065\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0026\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0022\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0020\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0027\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0020\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0016\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0016\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0015\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0016\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0015\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0013\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0014\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0012\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0011\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0012\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0015\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0012\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0011\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0012\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0010\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0010\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 8.8567e-04\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 9.4018e-04\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0014\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 9.4052e-04\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 8.6171e-04\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 8.6508e-04\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 8.2462e-04\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 9.0448e-04\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 8.5606e-04\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0011\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 8.7389e-04\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 8.7788e-04\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 7.3805e-04\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 8.5155e-04\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 8.1975e-04\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 7.0957e-04\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 7.1619e-04\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 7.1989e-04\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 7.7467e-04\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 6.6260e-04\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 7.4615e-04\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 7.4524e-04\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 8.6093e-04\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 6.3855e-04\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 7.3121e-04\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 7.3206e-04\n",
      "17/17 [==============================] - 1s 8ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 22ms/step - loss: 0.0148\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0038\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0041\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0037\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0035\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0037\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0034\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0041\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0035\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0033\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0026\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0030\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0030\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0027\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0028\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0027\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0026\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0026\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0022\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0022\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0026\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0022\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0020\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0020\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0022\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0020\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0019\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0026\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0018\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0019\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0017\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0017\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0015\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0016\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0013\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0014\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0014\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0014\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0017\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0014\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 21ms/step - loss: 0.0209\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0057\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0059\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0049\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0044\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0047\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0038\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0039\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0035\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0046\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0034\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0036\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0033\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0034\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0030\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0030\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0025\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0024\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0020\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0018\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0017\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0017\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0016\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0015\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0016\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0015\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0016\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0015\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0015\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0015\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0014\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0015\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 21ms/step - loss: 0.0256\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0070\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0060\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0062\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0057\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0059\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0049\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0048\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0047\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0040\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0039\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0037\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0041\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0036\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0037\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0035\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0034\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0027\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0029\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0026\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0030\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0030\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0027\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0027\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0025\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0029\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0024\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0024\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0022\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0022\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0020\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0024\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0022\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0020\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0019\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0020\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 3s 26ms/step - loss: 0.0669\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0186\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0161\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0132\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0137\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0117\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0114\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0131\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0119\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0098\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0109\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0100\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0113\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0101\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0096\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0086\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0078\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0078\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0080\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0095\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0082\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0069\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0070\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0066\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0078\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0074\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0064\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0065\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0058\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0055\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0063\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0066\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0059\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0069\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0058\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0055\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0052\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0065\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0065\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0056\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0059\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0055\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0051\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0052\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0051\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0046\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0064\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0059\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0048\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0050\n",
      "17/17 [==============================] - 1s 6ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 21ms/step - loss: 0.0203\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0075\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0068\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0066\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0052\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0063\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0049\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0052\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0043\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0045\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0046\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0037\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0038\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0042\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0036\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0042\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0041\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0034\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0029\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0032\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0028\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0028\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0026\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0025\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0027\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0027\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0025\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0020\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0023\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0020\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0020\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0020\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0021\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0021\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0019\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0018\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0017\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0019\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 21ms/step - loss: 0.0313\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0111\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0101\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0086\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0075\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0071\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0079\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0057\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0060\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0055\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0048\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0052\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0049\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0046\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0040\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0044\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0045\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0044\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0040\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0036\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0038\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0038\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0035\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0034\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0032\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0034\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0039\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0033\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0033\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0032\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0030\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0029\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0028\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0026\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0028\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0030\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0025\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0025\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0025\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0022\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0022\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 21ms/step - loss: 0.0168\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0049\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0050\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0046\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0042\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0048\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0040\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0035\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0039\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0034\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0044\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0035\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0031\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0028\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0030\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0028\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0029\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0030\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0026\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0026\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0022\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0022\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0023\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0027\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0026\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0021\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0020\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0026\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0029\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0019\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0021\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0024\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0019\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0021\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0017\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0017\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0017\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0021\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0019\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0018\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0017\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 22ms/step - loss: 0.0432\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0146\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0117\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0097\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0104\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0086\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0092\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0082\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0063\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0063\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0078\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0057\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0058\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0054\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0057\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0059\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0059\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0047\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0050\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0049\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0056\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0047\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0045\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0048\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0044\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0042\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0041\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0044\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0040\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0040\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0040\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0039\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0039\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0040\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0038\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0039\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0037\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0034\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0032\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0033\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0038\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0035\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0032\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0032\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0034\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0030\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0029\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0029\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0032\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0039\n",
      "17/17 [==============================] - 1s 7ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 23ms/step - loss: 0.0273\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0062\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0059\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0058\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0050\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0046\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0041\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0039\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0034\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0040\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0039\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0033\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0035\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0036\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0036\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0033\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0029\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0032\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0030\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0029\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0025\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0027\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0028\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0025\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0031\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0022\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0021\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0024\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0024\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0022\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0020\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0021\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0018\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0018\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0018\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0021\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0020\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0018\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0017\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0019\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0020\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0016\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0018\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0017\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0017\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0015\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0019\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0015\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0015\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0016\n",
      "17/17 [==============================] - 1s 10ms/step\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3s 22ms/step - loss: 0.0163\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0057\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0051\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0042\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0047\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0046\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0041\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0041\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0040\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0035\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0036\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0033\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0028\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0034\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0028\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0031\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0026\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0024\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0025\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0023\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0022\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0024\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0025\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0025\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0021\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0024\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0023\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0019\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0022\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0020\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0019\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0021\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0019\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0020\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0021\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0020\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0018\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0020\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0025\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0020\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0017\n",
      "Epoch 42/50\n",
      "22/45 [=============>................] - ETA: 0s - loss: 0.0020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sunyihan/Desktop/Coding Test 18June/Stock5.ipynb 单元格 11\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m stock \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(stock_dict\u001b[39m.\u001b[39mkeys()):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# uncomment the line above and comment the line below to iterate through all the stocks \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# for stock in [random.choice(list(stock_dict.keys()))]:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     ML_result \u001b[39m=\u001b[39m ML_model(stock_dict[stock]\u001b[39m.\u001b[39mcopy())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     LSTM_result \u001b[39m=\u001b[39m LSTM_model(stock_dict[stock]\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     test_result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([ML_result, LSTM_result], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdrop_duplicates()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     test_set \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([test_set, test_result], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32m/Users/sunyihan/Desktop/Coding Test 18June/Stock5.ipynb 单元格 11\u001b[0m in \u001b[0;36mLSTM_model\u001b[0;34m(stock_df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m regressor\u001b[39m.\u001b[39madd(Dense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m regressor\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m regressor\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m xtest_price \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sunyihan/Desktop/Coding%20Test%2018June/Stock5.ipynb#X13sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m xtest_volume \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# apply ML algorithms on each stock\n",
    "test_set = pd.DataFrame()\n",
    "\n",
    "for stock in list(stock_dict.keys()):\n",
    "    # uncomment the line above and comment the line below to iterate through all the stocks \n",
    "# for stock in [random.choice(list(stock_dict.keys()))]:\n",
    "    ML_result = ML_model(stock_dict[stock].copy())\n",
    "    LSTM_result = LSTM_model(stock_dict[stock].copy())\n",
    "    test_result = pd.concat([ML_result, LSTM_result], axis=1).drop_duplicates()\n",
    "    test_set = pd.concat([test_set, test_result], axis=0)\n",
    "\n",
    "\n",
    "## Note: This part was not completely finished due to time limit. Only part of the results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ae00267",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc08f5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>pred_price_SVM</th>\n",
       "      <th>pred_price_RF</th>\n",
       "      <th>pred_price_GBM</th>\n",
       "      <th>pred_price_LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6301 JT</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2129.1624</td>\n",
       "      <td>8288500</td>\n",
       "      <td>2019</td>\n",
       "      <td>2043.846443</td>\n",
       "      <td>2192.032629</td>\n",
       "      <td>2195.132148</td>\n",
       "      <td>2174.094971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6301 JT</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2275.7284</td>\n",
       "      <td>6711000</td>\n",
       "      <td>2019</td>\n",
       "      <td>2039.949457</td>\n",
       "      <td>2155.446811</td>\n",
       "      <td>2152.040612</td>\n",
       "      <td>2164.656738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6301 JT</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2300.854</td>\n",
       "      <td>6721500</td>\n",
       "      <td>2019</td>\n",
       "      <td>2037.450294</td>\n",
       "      <td>2294.8768</td>\n",
       "      <td>2293.01569</td>\n",
       "      <td>2183.822754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6301 JT</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>2373.9044</td>\n",
       "      <td>6645900</td>\n",
       "      <td>2019</td>\n",
       "      <td>2033.645516</td>\n",
       "      <td>2297.973262</td>\n",
       "      <td>2288.165875</td>\n",
       "      <td>2209.687988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6301 JT</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>2360.411</td>\n",
       "      <td>5910000</td>\n",
       "      <td>2019</td>\n",
       "      <td>2030.337745</td>\n",
       "      <td>2368.14555</td>\n",
       "      <td>2368.174291</td>\n",
       "      <td>2248.574463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>6504 JT</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>563000</td>\n",
       "      <td>2021</td>\n",
       "      <td>2290.940481</td>\n",
       "      <td>4321.67037</td>\n",
       "      <td>4213.879559</td>\n",
       "      <td>4170.245605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>6504 JT</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>4775.0</td>\n",
       "      <td>487100</td>\n",
       "      <td>2021</td>\n",
       "      <td>2290.530843</td>\n",
       "      <td>4330.911916</td>\n",
       "      <td>4224.744946</td>\n",
       "      <td>4194.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>6504 JT</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>449400</td>\n",
       "      <td>2021</td>\n",
       "      <td>2288.939472</td>\n",
       "      <td>4303.590587</td>\n",
       "      <td>4265.959865</td>\n",
       "      <td>4214.552734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>6504 JT</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>4790.0</td>\n",
       "      <td>733200</td>\n",
       "      <td>2021</td>\n",
       "      <td>2288.614862</td>\n",
       "      <td>4325.470405</td>\n",
       "      <td>4246.570936</td>\n",
       "      <td>4232.743164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>6504 JT</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>630700</td>\n",
       "      <td>2021</td>\n",
       "      <td>2288.221642</td>\n",
       "      <td>4325.793979</td>\n",
       "      <td>4250.361088</td>\n",
       "      <td>4245.800781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5885 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock       date      price   volume  year pred_price_SVM  \\\n",
       "0    6301 JT 2019-01-04  2129.1624  8288500  2019    2043.846443   \n",
       "1    6301 JT 2019-01-07  2275.7284  6711000  2019    2039.949457   \n",
       "2    6301 JT 2019-01-08   2300.854  6721500  2019    2037.450294   \n",
       "3    6301 JT 2019-01-09  2373.9044  6645900  2019    2033.645516   \n",
       "4    6301 JT 2019-01-10   2360.411  5910000  2019    2030.337745   \n",
       "..       ...        ...        ...      ...   ...            ...   \n",
       "530  6504 JT 2021-03-15     4800.0   563000  2021    2290.940481   \n",
       "531  6504 JT 2021-03-16     4775.0   487100  2021    2290.530843   \n",
       "532  6504 JT 2021-03-17     4800.0   449400  2021    2288.939472   \n",
       "533  6504 JT 2021-03-18     4790.0   733200  2021    2288.614862   \n",
       "534  6504 JT 2021-03-19     4815.0   630700  2021    2288.221642   \n",
       "\n",
       "    pred_price_RF pred_price_GBM pred_price_LSTM  \n",
       "0     2192.032629    2195.132148     2174.094971  \n",
       "1     2155.446811    2152.040612     2164.656738  \n",
       "2       2294.8768     2293.01569     2183.822754  \n",
       "3     2297.973262    2288.165875     2209.687988  \n",
       "4      2368.14555    2368.174291     2248.574463  \n",
       "..            ...            ...             ...  \n",
       "530    4321.67037    4213.879559     4170.245605  \n",
       "531   4330.911916    4224.744946     4194.691406  \n",
       "532   4303.590587    4265.959865     4214.552734  \n",
       "533   4325.470405    4246.570936     4232.743164  \n",
       "534   4325.793979    4250.361088     4245.800781  \n",
       "\n",
       "[5885 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5d24ac6",
   "metadata": {},
   "source": [
    "## 3 - Backtesting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b04c16e4",
   "metadata": {},
   "source": [
    "### 3.1 - Generate the position of each stock on each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c5eeaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set1 = test_set.copy()\n",
    "# get the return should we buy the stock at the close price of the day and sell it at the close price of the next day\n",
    "test_set1['return'] = (test_set1.groupby('stock')['price'].shift(-1) - test_set1['price'])/test_set1['price']\n",
    "\n",
    "# get the predicted price for the next day    \n",
    "test_set1['predicted_price'] = test_set1[['pred_price_SVM', 'pred_price_RF', 'pred_price_GBM']].mean(axis=1)\n",
    "test_set1['predicted_price1'] = test_set1.groupby('stock')['predicted_price'].shift(-1)\n",
    "\n",
    "# generate the undervalued/overvalued signal\n",
    "test_set1['under_valued'] = test_set1['predicted_price1'] - test_set1['price']\n",
    "\n",
    "# select the 10% most under-valuated stocks and 10% most over-valued stocks for each day; generate the long-short position\n",
    "test_set1['under_valued_rank'] = test_set1.groupby('date')['under_valued'].rank(ascending=False)\n",
    "test_set1['under_valued_rank'] = test_set1['under_valued_rank'] / test_set1.groupby('date')['under_valued_rank'].transform('max')\n",
    "test_set1['position'] = test_set1['under_valued_rank'].apply(lambda x: 1 if x <= 0.1 else (-1 if x >= 0.9 else 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "604ff17c",
   "metadata": {},
   "source": [
    "### 3.2 - Calculate the daily return of the strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b13d5400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>-0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>0.018005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>0.010172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-10</th>\n",
       "      <td>0.020964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              return\n",
       "2019-01-04 -0.001884\n",
       "2019-01-07  0.018005\n",
       "2019-01-08  0.010172\n",
       "2019-01-09  0.000998\n",
       "2019-01-10  0.020964"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_df = pd.DataFrame(index=test_set1.date.unique(), columns=['return'])\n",
    "\n",
    "for date in test_set1.date.unique():\n",
    "    df_long = test_set1[(test_set1.date == date) & (test_set1.position == 1)]\n",
    "    return_long = np.mean(np.array(df_long['return'])+1)\n",
    "    df_short = test_set1[(test_set1.date == date) & (test_set1.position == -1)]\n",
    "    return_short = np.mean(np.array(df_short['return'])+1)\n",
    "    return_df.loc[date, 'return'] = return_long - return_short\n",
    "return_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8282c471",
   "metadata": {},
   "source": [
    "### 3.3 - Evaluation Criteria to be evaluated\n",
    "- Annulized Return\n",
    "- Annulized Volatility\n",
    "- Sharpe Ratio = (Annulized Return - Risk Free return) / Annulized Volatility\n",
    "- Maximum Drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef18eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
